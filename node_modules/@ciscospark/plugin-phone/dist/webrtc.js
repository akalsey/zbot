'use strict';

Object.defineProperty(exports, "__esModule", {
  value: true
});
exports.addStream = exports.end = exports.acceptAnswer = exports.createOffer = exports.stopSendingVideo = exports.stopSendingAudio = exports.startSendingVideo = exports.startSendingAudio = exports.startReceivingVideo = exports.startReceivingAudio = exports.stopReceivingVideo = exports.stopReceivingAudio = undefined;

var _defaults = require('lodash/defaults');

var _defaults2 = _interopRequireDefault(_defaults);

var _find = require('lodash/find');

var _find2 = _interopRequireDefault(_find);

var _promise = require('babel-runtime/core-js/promise');

var _promise2 = _interopRequireDefault(_promise);

var _curry = require('lodash/curry');

var _curry2 = _interopRequireDefault(_curry);

var _map = require('babel-runtime/core-js/map');

var _map2 = _interopRequireDefault(_map);

exports.getUserMedia = getUserMedia;
exports.mediaDirection = mediaDirection;

require('webrtc-adapter');

var _sdpTransform = require('sdp-transform');

var _sdpTransform2 = _interopRequireDefault(_sdpTransform);

var _common = require('@ciscospark/common');

var _mapUtils = require('./map-utils');

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

/**!
 *
 * Copyright (c) 2015 Cisco Systems, Inc. See LICENSE file.
 * @private
 */

/* eslint max-nested-callbacks: [0] */

var tracksByKindByStream = new _map2.default();
var storeMediaTrackByKindByStream = (0, _mapUtils.addToMappedWeakMappedSet)(tracksByKindByStream);
var getMediaTracksByKindByStream = (0, _mapUtils.getMappedWeakMappedSet)(tracksByKindByStream);
var getVideoTracksByStream = getMediaTracksByKindByStream('video');
var getAudioTracksByStream = getMediaTracksByKindByStream('audio');

var startSendingMedia = (0, _curry2.default)(function (kind, pc) {
  var foundKind = false;
  pc.getLocalStreams().forEach(function (stream) {
    // Find all the tracks we've removed from the stream/pc so we can readd them
    var tracks = getMediaTracksByKindByStream(kind, stream);
    tracks.forEach(function (track) {
      foundKind = foundKind || true;
      track.enabled = true;
      // Because adapter.js doesn't actually hide all the cross browser
      // inconsistencies
      if (pc.addTrack) {
        pc.addTrack(track, stream);
      } else {
        stream.addTrack(track);
      }
    });
    tracks.delete(stream);
  });

  // If we didn't find any tracks for this stream/pc, we need to get new media
  if (!foundKind) {
    var constraints = {
      audio: kind === 'audio',
      video: kind === 'video'
    };

    return getUserMedia(constraints).then(function (stream) {
      return addStream(pc, stream);
    });
  }

  return _promise2.default.resolve();
});

var stopSendingMedia = (0, _curry2.default)(function (kind, pc) {
  pc.getLocalStreams().forEach(function (stream) {
    stream.getTracks().forEach(function (track) {
      if (track.kind === kind) {
        track.enabled = false;
        // Store the tracks so we can add them back later (should the user want
        // to mute/unmute)
        storeMediaTrackByKindByStream(kind, stream, track);
        if (pc.removeTrack) {
          var sender = (0, _find2.default)(pc.getSenders(), function (s) {
            return s.track === track;
          });
          pc.removeTrack(sender);
        } else {
          stream.removeTrack(track);
        }
      }
    });
  });
});

var startReceivingMedia = (0, _curry2.default)(function (kind, pc) {
  var foundKind = false;
  pc.getRemoteStreams().forEach(function (stream) {
    // Find all the tracks we've removed from the stream/pc so we can readd them
    var tracks = getMediaTracksByKindByStream(kind, stream);
    tracks.forEach(function (track) {
      foundKind = foundKind || true;
      track.enabled = true;
      // Because adapter.js doesn't actually hide all the cross browser
      // inconsistencies
      if (pc.addTrack) {
        pc.addTrack(track, stream);
      } else {
        stream.addTrack(track);
      }
    });
    tracks.delete(stream);
  });

  return _promise2.default.resolve();
});

var stopReceivingMedia = (0, _curry2.default)(function (kind, pc) {
  pc.getRemoteStreams().forEach(function (stream) {
    stream.getTracks().forEach(function (track) {
      if (track.kind === kind) {
        track.enabled = false;
        // Store the tracks so we can add them back later (should the user want
        // to mute/unmute)
        storeMediaTrackByKindByStream(kind, stream, track);
        if (pc.removeTrack) {
          var receiver = (0, _find2.default)(pc.getSenders(), function (r) {
            return r.track === track;
          });

          try {
            pc.removeTrack(receiver);
          } catch (reason) {
            // eslint-disable-next-line no-console
            console.warn('webrtc: this browser has limited support for renegotiation; receiving ' + kind + ' has been stopped, but will not be renegotiated');
          }
        } else {
          stream.removeTrack(track);
        }
      }
    });
  });
});

var stopReceivingAudio = exports.stopReceivingAudio = stopReceivingMedia('audio');
var stopReceivingVideo = exports.stopReceivingVideo = stopReceivingMedia('video');
var startReceivingAudio = exports.startReceivingAudio = startReceivingMedia('audio');
var startReceivingVideo = exports.startReceivingVideo = startReceivingMedia('video');

/**
 * Adds a bandwith limit line to the sdp; without this line, calling fails
 * @param {string} sdp SDP
 * @private
 * @returns {string} The modified SDP
 */
function limitBandwith(sdp) {
  // TODO can limitBandwith be done with the sender/reciever apis?
  return sdp.split('\r\n').reduce(function (lines, line) {
    lines.push(line);
    if (line.startsWith('m=')) {
      lines.push('b=TIAS:' + (line.includes('audio') ? 64000 : 1000000));
    }
    return lines;
  }, []).join('\r\n');
}

/**
 * Ends all streams for the specifed RTCPeerConnection
 * @param {RTCPeerConnection} pc The RTCPeerConnection for which to end all
 * streams
 * @private
 * @returns {undefined}
 */
function endAllStreams(pc) {
  reattachTracks(pc);
  pc.getLocalStreams().forEach(stopStream);
  pc.getRemoteStreams().forEach(stopStream);
}

/**
 * Stops the specifed stream's tracks and the stream (depending on browser
 * capabilities)
 * @param {MediaStream} stream The MediaStream to stop
 * @private
 * @returns {undefined}
 */
function stopStream(stream) {
  // need to reattach any removed tracks (even if they're stopped) to make sure
  // the camera gets turned off.
  if (stream.getTracks) {
    stream.getTracks().forEach(function (track) {
      return track.stop();
    });
  }

  if (stream.stop) {
    stream.stop();
  }
}

/**
 * Attaches all tracks that were removed from the specifed RTCPeerConnection
 * (e.g. while muting said tracks). Without reattaching them, the camera may
 * never turn off
 * @param {RTCPeerConnection} pc The RTCPeerConnection for which to reattach tracks
 * @private
 * @returns {undefined}
 */
function reattachTracks(pc) {
  pc.getLocalStreams().forEach(reattachTracksForStream);
}

/**
 * Reattaches tracks for specifed stream
 * @param {MediaStream} stream The MediaStream to which to reattach tracks
 * @private
 * @returns {undefined}
 */
function reattachTracksForStream(stream) {
  var vt = getVideoTracksByStream(stream);
  vt.forEach(function (track) {
    return stream.addTrack(track);
  });
  vt.clear();

  var at = getAudioTracksByStream(stream);
  at.forEach(function (track) {
    return stream.addTrack(track);
  });
  at.clear();
}

/**
 * Stops sending audio via the specifed RTCPeerConnection
 * @param {RTCPeerConnection} pc The RTCPeerConnection for which to stop audio
 * @private
 * @returns {Promise}
 */
var startSendingAudio = exports.startSendingAudio = startSendingMedia('audio');
/**
 * Stops sending video via the specifed RTCPeerConnection
 * @param {RTCPeerConnection} pc The RTCPeerConnection for which to stop video
 * @private
 * @returns {Promise}
 */
var startSendingVideo = exports.startSendingVideo = startSendingMedia('video');
/**
 * Starts sending audio via the specifed RTCPeerConnection
 * @param {RTCPeerConnection} pc The RTCPeerConnection for which to start audio
 * @private
 * @returns {Promise}
 */
var stopSendingAudio = exports.stopSendingAudio = stopSendingMedia('audio');
/**
 * Stops sending video via the specifed RTCPeerConnection
 * @param {RTCPeerConnection} pc The RTCPeerConnection for which to start video
 * @private
 * @returns {Promise}
 */
var stopSendingVideo = exports.stopSendingVideo = stopSendingMedia('video');

/**
 * Wrapper around navigator.mediaDevices.getUserMedia()
 * @param {MediaStreamConstraints} constraints if NODE_ENV is `test`, will
 * automatically add `{fake: true}`. If this is problematic for your use case,
 * you'll need to explicitly include `{fake: false}`
 * @private
 * @returns {Promise<MediaStream>} The resultant MediaStream
 */
function getUserMedia(constraints) {
  (0, _defaults2.default)(constraints, { fake: process.env.NODE_ENV === 'test' });
  return navigator.mediaDevices.getUserMedia(constraints);
}

/**
 * Creates an offer sdp based on the state of the specifed RTCPeerConnection and
 * offer options
 * @param {RTCPeerConnection} pc
 * @param { RTCOfferOptions} offerOptions
 * @private
 * @returns {Promise<string>} Resolves with the offer sdp
 */
var createOffer = exports.createOffer = (0, _curry2.default)(function (pc, offerOptions) {
  offerOptions = offerOptions || {};
  (0, _defaults2.default)(offerOptions, {
    offerToReceiveVideo: true,
    offerToReceiveAudio: true
  });

  var promise = new _promise2.default(function (resolve) {
    pc.onicecandidate = function (event) {
      if (!event.candidate) {
        pc.onicecandidate = undefined;
        resolve();
      }
    };

    setTimeout(function () {
      pc.onicecandidate = undefined;
      resolve();
    }, 500);
  });

  return pc.createOffer(offerOptions).then((0, _common.tap)(function (offer) {
    offer.sdp = limitBandwith(offer.sdp);
  })).then((0, _common.tap)(function (offer) {
    if (process.env.LOG_SDP) {
      // eslint-disable-next-line no-console
      console.log('offer', offer.sdp);
    }
  })).then(function (offer) {
    return pc.setLocalDescription(offer);
  }).then(function () {
    return _promise2.default.resolve(promise);
  })
  // Apparently chrome somehow moves the bandwith limit out of the video
  // section, so we need to reapply it.
  .then(function () {
    return limitBandwith(pc.localDescription.sdp);
  });
});

/**
 * Applies an incoming answer sdp to the specifed RTCPeerConnection
 * @param {RTCPeerConnection} pc
 * @param {string} sdp
 * @private
 * @returns {Promise}
 */
var acceptAnswer = exports.acceptAnswer = (0, _curry2.default)(function (pc, sdp) {
  if (process.env.LOG_SDP) {
    // eslint-disable-next-line no-console
    console.log('answer', sdp);
  }
  return pc.setRemoteDescription(new RTCSessionDescription({
    sdp: sdp,
    type: 'answer'
  }));
});

/**
 * Terminates the specifed RTCPeerConnection
 * @param {RTCPeerConnection} pc
 * @private
 * @returns {undefined}
 */
var end = exports.end = (0, _curry2.default)(function (pc) {
  if (pc.signalingState !== 'closed') {
    endAllStreams(pc);
    pc.close();
  }
});

var curriedAddStream = (0, _curry2.default)(addStream);

/**
 * Adds the specifed stream to the specifed RTCPeerConnection
 * @name addStream
 * @param {PeerConnection} pc The RTCPeerConnection to which to add the stream
 * @param {MediaStream} stream The stream to add
 * @private
 * @returns {undefined}
 */
exports.addStream = curriedAddStream;

/**
 * Adds the specifed stream to the specifed RTCPeerConnection
 * @param {PeerConnection} pc The RTCPeerConnection to which to add the stream
 * @param {MediaStream} stream The stream to add
 * @private
 * @returns {undefined}
 */

function addStream(pc, stream) {
  // TODO do either of these return promises?
  if (pc.addTrack) {
    stream.getTracks().forEach(function (track) {
      return pc.addTrack(track, stream);
    });
  } else {
    pc.addStream(stream);
  }
}

/**
 * returns the direction line for the specifed media type.
 * @param {string} type
 * @param {RTCPeerConnection} pc
 * @private
 * @returns {string}
 */
function mediaDirection(type, pc) {
  if (pc.connectionState === 'closed' || pc.signalingState === 'closed') {
    return 'inactive';
  }

  if (!pc.localDescription) {
    return 'inactive';
  }
  var sdp = _sdpTransform2.default.parse(pc.localDescription.sdp);
  var media = (0, _find2.default)(sdp.media, { type: type });
  if (!media) {
    return 'inactive';
  }

  if (type === 'audio' && media.direction === 'sendonly') {
    var remoteSdp = _sdpTransform2.default.parse(pc.remoteDescription.sdp);
    var remoteMedia = (0, _find2.default)(remoteSdp.media, { type: type });
    if (remoteMedia && remoteMedia.direction === 'inactive') {
      return 'inactive';
    }
  }

  return media.direction;
}
//# sourceMappingURL=webrtc.js.map
