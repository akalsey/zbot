'use strict';

Object.defineProperty(exports, "__esModule", {
  value: true
});
exports.levels = undefined;

var _toConsumableArray2 = require('babel-runtime/helpers/toConsumableArray');

var _toConsumableArray3 = _interopRequireDefault(_toConsumableArray2);

var _cloneDeep = require('lodash/cloneDeep');

var _cloneDeep2 = _interopRequireDefault(_cloneDeep);

var _deleteProperty = require('babel-runtime/core-js/reflect/delete-property');

var _deleteProperty2 = _interopRequireDefault(_deleteProperty);

var _isString = require('lodash/isString');

var _isString2 = _interopRequireDefault(_isString);

var _isObject = require('lodash/isObject');

var _isObject2 = _interopRequireDefault(_isObject);

var _isArray = require('lodash/isArray');

var _isArray2 = _interopRequireDefault(_isArray);

var _keys = require('babel-runtime/core-js/object/keys');

var _keys2 = _interopRequireDefault(_keys);

var _common = require('@ciscospark/common');

var _sparkCore = require('@ciscospark/spark-core');

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

/**!
 *
 * Copyright (c) 2015-2016 Cisco Systems, Inc. See LICENSE file.
 * @private
 */

var precedence = {
  silent: 0,
  error: 1,
  warn: 2,
  log: 3,
  info: 4,
  debug: 5,
  trace: 6
};

var levels = exports.levels = (0, _keys2.default)(precedence).filter(function (level) {
  return level !== 'silent';
});

var fallbacks = {
  error: ['log'],
  warn: ['error', 'log'],
  info: ['log'],
  debug: ['info', 'log'],
  trace: ['debug', 'info', 'log']
};

var authTokenKeyPattern = /[Aa]uthorization/;

/**
 * Recursively strips "authorization" fields from the specified object
 * @param {Object} object
 * @returns {Object}
 */
function walkAndFilter(object) {
  if ((0, _isArray2.default)(object)) {
    return object.map(walkAndFilter);
  }
  if (!(0, _isObject2.default)(object)) {
    if ((0, _isString2.default)(object)) {
      if (_common.patterns.email.test(object)) {
        return '-- REDACTED --';
      }
    }
    return object;
  }
  for (var key in object) {
    if (authTokenKeyPattern.test(key)) {
      (0, _deleteProperty2.default)(object, key);
    } else {
      object[key] = walkAndFilter(object[key]);
    }
  }
  return object;
}

var Logger = _sparkCore.SparkPlugin.extend({
  namespace: 'Logger',

  derived: {
    level: {
      cache: false,
      fn: function fn() {
        return this.getCurrentLevel();
      }
    }
  },
  session: {
    buffer: {
      type: 'array',
      default: function _default() {
        return [];
      }
    }
  },

  /**
   * Ensures auth headers don't get printed in logs
   * @param {Array<mixed>} args
   * @private
   * @returns {Array<mixed>}
   */
  filter: function filter() {
    for (var _len = arguments.length, args = Array(_len), _key = 0; _key < _len; _key++) {
      args[_key] = arguments[_key];
    }

    return args.map(function (arg) {
      // SparkHttpError already ensures auth tokens don't get printed, so, no
      // need to alter it here.
      if (arg instanceof Error) {
        // karma logs won't print subclassed errors correctly, so we need
        // explicitly call their tostring methods.
        if (process.env.NODE_ENV === 'test' && typeof window !== 'undefined') {
          var ret = arg.toString();
          ret += 'BEGIN STACK';
          ret += arg.stack;
          ret += 'END STACK';
          return ret;
        }

        return arg;
      }

      arg = (0, _cloneDeep2.default)(arg);
      return walkAndFilter(arg);
    });
  },


  /**
   * Determines if the current level allows logs at the speicified level to be
   * printed
   * @param {string} level
   * @private
   * @returns {boolean}
   */
  shouldPrint: function shouldPrint(level) {
    return precedence[level] <= precedence[this.getCurrentLevel()];
  },


  /**
   * Indicates the current log level based on env vars, feature toggles, and
   * user type.
   * @instance
   * @memberof Logger
   * @private
   * @returns {string}
   */
  // eslint-disable-next-line complexity
  getCurrentLevel: function getCurrentLevel() {
    // If a level has been explicitly set via config, alway use it.
    if (this.config.level) {
      return this.config.level;
    }

    if (levels.includes(process.env.CISCOSPARK_LOG_LEVEL)) {
      return process.env.CISCOSPARK_LOG_LEVEL;
    }

    // Always use debug-level logging in test mode;
    if (process.env.NODE_ENV === 'test') {
      return 'trace';
    }

    // Use server-side-feature toggles to configure log levels
    var level = this.spark.device && this.spark.device.features.developer.get('log-level');
    if (level) {
      if (levels.includes(level)) {
        return level;
      }
    }

    return 'error';
  }
});

levels.forEach(function (level) {
  var impls = fallbacks[level];
  var impl = level;
  if (impls) {
    impls = impls.slice();
    // eslint-disable-next-line no-console
    while (!console[impl]) {
      impl = impls.pop();
    }
  }

  Logger.prototype[level] = function wrappedConsoleMethod() {
    try {
      var filtered = this.filter.apply(this, arguments);
      var stringified = filtered.map(function (item) {
        if (item instanceof _sparkCore.SparkHttpError) {
          return item.toString();
        }
        return item;
      });

      if (this.shouldPrint(level)) {
        var _console;

        var toPrint = typeof window === 'undefined' ? filtered : stringified;
        // eslint-disable-next-line no-console
        (_console = console)[impl].apply(_console, (0, _toConsumableArray3.default)(toPrint));
      }

      stringified.unshift(Date.now());
      this.buffer.push(stringified);
      if (this.buffer.length > this.config.historyLength) {
        this.buffer.shift();
      }
    } catch (reason) {
      /* istanbul ignore next */
      // eslint-disable-next-line no-console
      console.warn('failed to execute Logger#' + level, reason);
    }
  };
});

exports.default = Logger;
//# sourceMappingURL=logger.js.map
